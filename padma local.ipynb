{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n15sDYH4UJVy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CubvQ370HWpP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cud7PbDZMMPZ"
      },
      "source": [
        "The encoder and decoder are mirrored networks consisting of two layers. In the encoder the we take the input data to a hidden dimension through a linear layer and then we pass the hidden state to two different linear layers outputting the mean and standard deviation of the latent distribution respectively.\n",
        "\n",
        "We then sample from the latent distribution and input it to the decoder that in turn outputs a vector of the same shape as the input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO0zNIlyMQ1T"
      },
      "source": [
        "### Creating the latent space using an encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT8mQGOdNxq8"
      },
      "outputs": [],
      "source": [
        "# creating helper print module\n",
        "class PrintSize(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(PrintSize, self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(x.shape)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLgC0kKfHrL3"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "INPUT_DIM = 224\n",
        "Z_DIM = 20\n",
        "H_DIM = 20\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 132\n",
        "LR_RATE = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "218/4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "1458/H_DIM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBXtgpSyHfwO"
      },
      "outputs": [],
      "source": [
        "class VariationalAutoEncoder(nn.Module):\n",
        "    def __init__(self, input_dim=INPUT_DIM, z_dim=Z_DIM, h_dim=H_DIM, kernel_size=4, hidden_channels=16):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder\n",
        "\n",
        "        # one for mu and one for stds, note how we only output\n",
        "        # diagonal values of covariance matrix. Here we assume\n",
        "        # the pixels are conditionally independent\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, hidden_channels, kernel_size)\n",
        "        self.conv2 = nn.Conv2d(hidden_channels, 1, kernel_size)\n",
        "        self.vector_length = 218\n",
        "        self.pool1 = nn.AdaptiveAvgPool2d((int(self.vector_length/2), int(self.vector_length/2)))\n",
        "        self.pool2 = nn.AdaptiveAvgPool2d((int(self.vector_length/4), int(self.vector_length/4)))\n",
        "        self.img_2hid = nn.Linear(int(self.vector_length/4), h_dim)\n",
        "        # self.fl1 = nn.Flatten()\n",
        "        # self.hid_2hid = nn.Linear(int(self.vector_length/4)*h_dim, h_dim*8)\n",
        "        # self.hid_2hid2 = nn.Linear(h_dim*8, h_dim*4)\n",
        "        self.hid_2z = nn.Linear(h_dim, z_dim)\n",
        "\n",
        "        self.z_2hid = nn.Linear(z_dim, h_dim)\n",
        "        self.hid_2img = nn.Linear(h_dim, int(self.vector_length/4))\n",
        "        self.convt1 = nn.ConvTranspose2d(1, hidden_channels, 2)\n",
        "        self.convt2 = nn.ConvTranspose2d(hidden_channels, 4, 3, stride=2)\n",
        "\n",
        "        self.convt3 = nn.ConvTranspose2d(4, 1, 4, stride=2)\n",
        "    \n",
        "    def encode(self, x):\n",
        "        z = F.relu(self.conv1(x))\n",
        "        z = F.relu(self.conv2(z))\n",
        "        z = self.pool1(z)\n",
        "        #print(f'after pool: {z.shape}')\n",
        "        z = self.pool2(z)\n",
        "        #print('after pool 2', z.shape)\n",
        "        z = self.img_2hid(z)\n",
        "        #print('downsampled image to hid:', z.shape)\n",
        "        z = self.hid_2z(z)\n",
        "        #print('hid_to_z', z.shape)\n",
        "        #print(f'full layer 1: {z.shape}')\n",
        "        return z\n",
        "    \n",
        "    def decode(self, z):\n",
        "        #x = z.reshape(z.shape[0], 1, self.vector_length, self.vector_length)\n",
        "        x = self.z_2hid(z)\n",
        "        x = self.hid_2img(x)\n",
        "        #print('hid_to_img', x.shape)\n",
        "        x = F.relu(self.convt1(x))\n",
        "        #print(f'conv transpose 1: {x.shape}')\n",
        "        x = F.relu(self.convt2(x))\n",
        "        #print(f'conv transpose 2: {x.shape}')\n",
        "        x = F.relu(self.convt3(x))\n",
        "        #print(f'conv transpose 3: {x.shape}')\n",
        "        #print(f'full layer 5: {x.shape}')\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        z_reparametrized = self.encode(x)\n",
        "\n",
        "        x_reconst = self.decode(z_reparametrized)\n",
        "        #print('RECONST', x_reconst.shape)\n",
        "        return x_reconst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1eymnahHuUu"
      },
      "outputs": [],
      "source": [
        "# Dataset loading\n",
        "# dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "# train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "from galaxy_datasets import gz2  # or gz_hubble, gz_candels, ...\n",
        "\n",
        "catalog, label_cols = gz2(root='/Users/padmavenkatraman/Documents/SSI/SSI_Projects/gz2/',train=True,download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "CJHPnOKfa80P",
        "outputId": "27cf1c1d-86de-499a-e27d-dfcf70e01204"
      },
      "outputs": [],
      "source": [
        "catalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "catalog['summary_val']=catalog['summary'].map({'smooth_round':1,'smooth_inbetween':2,'smooth_cigar':3,\\\n",
        "                                             'featured_without_bar_or_spiral':4,'edge_on_disk':5,'barred_spiral':6,\\\n",
        "                                             'unbarred_spiral':7,None:8})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "catalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fNuLqFD1V0AR",
        "outputId": "c0274336-9990-476d-8e8d-d5ab6276f6a7"
      },
      "outputs": [],
      "source": [
        "# from galaxy_datasets.pytorch.galaxy_datamodule import GalaxyDataModule\n",
        "\n",
        "# datamodule = GalaxyDataModule(\n",
        "#     catalog=catalog.sample(20000),\n",
        "#     label_cols =[],\n",
        "#     # optional args to specify augmentations\n",
        "# )\n",
        "\n",
        "# datamodule.prepare_data()\n",
        "# datamodule.setup()\n",
        "# '''\n",
        "# for images, labels in datamodule.train_dataloader():\n",
        "#     print(images.shape, labels.shape)\n",
        "#     break'''\n",
        "\n",
        "\n",
        "from galaxy_datasets.pytorch.galaxy_datamodule import GalaxyDataModule\n",
        "datamodule = GalaxyDataModule(\n",
        "    catalog = catalog[catalog['label']==1].sample(20000,replace=False),\n",
        "    label_cols = [])\n",
        "datamodule.prepare_data()\n",
        "datamodule.setup()\n",
        "train_data = datamodule.train_dataloader()\n",
        "val_data = datamodule.val_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_image(img_arr):\n",
        "  org_img = img_arr.cpu().detach().numpy()\n",
        "  org_img_shape = org_img.shape\n",
        "  print(f'image input dimensions = {org_img_shape}')\n",
        "  print(f'number of channels = {org_img_shape[0]}')\n",
        "  print(f'height = {org_img_shape[1]}')\n",
        "  print(f'width = {org_img_shape[2]}')\n",
        "\n",
        "  img = np.transpose(org_img, (1, 2, 0))\n",
        "  print(f'image plotting dimensions = {img.shape}')\n",
        "  plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_real_reconst(old, reconst):\n",
        "    fig, ax = plt.subplots(1, 2)\n",
        "    org_img_old = old.cpu().detach().numpy()\n",
        "    img_old = np.transpose(org_img_old, (1, 2, 0))\n",
        "    \n",
        "\n",
        "    org_img_new = reconst.cpu().detach().numpy()\n",
        "    img_new = np.transpose(org_img_new, (1, 2, 0))\n",
        "\n",
        "    ax[0].imshow(img_old)\n",
        "    ax[1].imshow(img_new)\n",
        "    ax[0].axis('off')\n",
        "    ax[1].axis('off')\n",
        "    plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrOAwn5ZH2CI"
      },
      "outputs": [],
      "source": [
        "def early_stopping(train_loss, validation_loss, min_delta_frac):\n",
        "    val_train_diff = (validation_loss - train_loss)/train_loss\n",
        "    if  val_train_diff > min_delta_frac:\n",
        "          print('Fractional Difference',val_train_diff)\n",
        "          return True\n",
        "\n",
        "# Define train function\n",
        "def train(num_epochs, model, optimizer, loss_fn, training_dataloader,val_dataloader):\n",
        "    # Start training\n",
        "    all_train_loss, all_val_loss = [], []\n",
        "    train_loss_list, val_loss_list = [], []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss_per_epoch, val_loss_per_epoch = [], []\n",
        "        loop = enumerate(training_dataloader)\n",
        "        print(f'epoch number = {epoch}')\n",
        "        for i, (x, _) in loop:\n",
        "            # Forward pass\n",
        "\n",
        "            x_reconst = model(x.to(device))\n",
        "            # print(x_reconst.shape, x.shape)\n",
        "            reconst_loss = loss_fn(x_reconst, x.to(device))\n",
        "            # kl_div = - torch.mean(1 + torch.log(sigma.pow(2)) - torch.linalg.vector_norm(mu) - sigma.pow(2))\n",
        "\n",
        "            loss = reconst_loss# + kl_div\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # loop.set_postfix(loss=loss.item())\n",
        "            loss_numpy = loss.cpu().detach().numpy()\n",
        "\n",
        "            train_loss_per_epoch.append(loss_numpy)\n",
        "            all_train_loss.append(loss_numpy)\n",
        "            \n",
        "\n",
        "            if i%10==0:\n",
        "              print('JUST TRAINED ANOTHER 10......')\n",
        "              plot_real_reconst(x[0], x_reconst[0])\n",
        "              with torch.no_grad():\n",
        "                for j, (x_val,_) in enumerate(val_dataloader):\n",
        "                  # validation\n",
        "                  x_reconst_val = model(x_val.to(device))\n",
        "                  reconst_loss_val = loss_fn(x_reconst_val, x_val.to(device))\n",
        "                  # kl_div_val = - torch.mean(1 + torch.log(sigma_val.pow(2)) - torch.linalg.vector_norm(mu_val) - sigma_val.pow(2))\n",
        "  #                reconst_loss_val = torch.sum((x_reconst - x_val).pow(2))\n",
        "  #                kl_div_val = -torch.mean(1 + torch.log(torch.linalg.vector_norm(sigma_val)) - torch.linalg.vector_norm(mu_val) - torch.linalg.vector_norm(sigma_val))\n",
        "                  val_loss = reconst_loss_val# + kl_div_val\n",
        "                  val_loss_numpy = val_loss.cpu().detach().numpy()\n",
        "                  val_loss_per_epoch.append(val_loss_numpy)\n",
        "                  all_val_loss.append(val_loss_numpy)\n",
        "                  \n",
        "            if len(train_loss_per_epoch)%20==0:\n",
        "                  print(f'Current Loss {train_loss_per_epoch[-1]}')\n",
        "        train_loss_list.append(np.mean(train_loss_per_epoch))\n",
        "        val_loss_list.append(np.mean(val_loss_per_epoch))\n",
        "        torch.save(\n",
        "            {'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': np.mean(train_loss_per_epoch),\n",
        "            'test_loss':np.mean(val_loss_per_epoch)\n",
        "        }, f'/Users/padmavenkatraman/Documents/SSI/SSI_Projects/model_save_files/{epoch}_6.pth')\n",
        "    return all_train_loss, all_val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = VariationalAutoEncoder(INPUT_DIM, Z_DIM).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR_RATE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJjblPYrHz59",
        "outputId": "419d12f7-1007-45d5-a70e-4eb3dbb6e94d"
      },
      "outputs": [],
      "source": [
        "# Initialize model, optimizer, loss\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "# Run training\n",
        "tr_loss, val_loss = train(NUM_EPOCHS, model, optimizer, loss_fn, train_data,val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trained = torch.load('/Users/padmavenkatraman/Documents/SSI/SSI_Projects/model_save_files/9_5_2.pth')\n",
        "model.load_state_dict(trained['model_state_dict'])\n",
        "optimizer.load_state_dict(trained['optimizer_state_dict'])\n",
        "epoch = trained['epoch']\n",
        "loss = trained['train_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = datamodule.test_dataloader()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datamodule2 = GalaxyDataModule(\n",
        "    catalog = catalog[catalog['summary_val']==3].sample(10000,replace=False),\n",
        "    label_cols = [])\n",
        "datamodule2.prepare_data()\n",
        "datamodule2.setup()\n",
        "test_data2 = datamodule2.test_dataloader()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datamodule3 = GalaxyDataModule(\n",
        "    catalog = catalog[catalog['label']==3].sample(1000,replace=False),\n",
        "    label_cols = [])\n",
        "datamodule3.prepare_data()\n",
        "datamodule3.setup()\n",
        "test_data3 = datamodule3.test_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_loop(testdata, num_loops):\n",
        "    test_loss_all = []\n",
        "    with torch.no_grad():\n",
        "        while len(test_loss_all) < num_loops:\n",
        "            for j, (xt,_) in enumerate(testdata):\n",
        "                \n",
        "                # validation\n",
        "                xrt = model(xt.to(device))\n",
        "                reconst_loss_val = loss_fn(xrt, xt.to(device))\n",
        "                # kl_div_val = - torch.mean(1 + torch.log(sigma_val.pow(2)) - torch.linalg.vector_norm(mu_val) - sigma_val.pow(2))\n",
        "        #                reconst_loss_val = torch.sum((x_reconst - x_val).pow(2))\n",
        "        #                kl_div_val = -torch.mean(1 + torch.log(torch.linalg.vector_norm(sigma_val)) - torch.linalg.vector_norm(mu_val) - torch.linalg.vector_norm(sigma_val))\n",
        "                test_loss = reconst_loss_val# + kl_div_val\n",
        "                test_loss_numpy = test_loss.cpu().detach().numpy()\n",
        "                test_loss_all.append(test_loss_numpy)\n",
        "                if len(test_loss_all)%10 == 0:\n",
        "                    plot_real_reconst(xt[0], xrt[0])\n",
        "    return test_loss_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_edge = test_loop(test_data3, 256)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_smooth = test_loop(test_data, 256)\n",
        "test_cigar = test_loop(test_data2, 256)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(test_smooth), len(test_cigar), len(test_edge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.hist(test_smooth[:88], bins=np.linspace(20,35, 50), density=True, edgecolor='white', alpha = 0.5, color='r', label='smooth rounded', );\n",
        "plt.hist(test_cigar, bins=np.linspace(20,35, 50), density=True, edgecolor='white', alpha = 0.5, color='b', label='smooth cigar');\n",
        "\n",
        "plt.hist(test_edge, bins=np.linspace(20,35, 50),density=True, edgecolor='white', alpha = 0.5, color='k', label='edge on');\n",
        "plt.xlabel(\"MSE Loss\")\n",
        "plt.title('reconstruction loss')\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_in_epoch_loss(losstype):\n",
        "    loss_list = []\n",
        "    for i in np.arange(10):\n",
        "        l =torch.load(f'/Users/padmavenkatraman/Documents/SSI/SSI_Projects/model_save_files/{i}_5.pth')[losstype]\n",
        "        loss_list.append(l)\n",
        "    for i in np.arange(10):\n",
        "        l =torch.load(f'/Users/padmavenkatraman/Documents/SSI/SSI_Projects/model_save_files/{i}_5_2.pth')[losstype]\n",
        "        loss_list.append(l)\n",
        "    return loss_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loss_list = read_in_epoch_loss('train_loss')\n",
        "val_loss_list = read_in_epoch_loss('test_loss')\n",
        "plt.plot(np.arange(len(train_loss_list)), train_loss_list, label='train loss', color='k')\n",
        "plt.plot(np.arange(len(val_loss_list)), val_loss_list, label='validation loss', color='r', alpha = 0.7)\n",
        "plt.yticks(np.linspace(min(val_loss_list), max(train_loss_list), 20))\n",
        "min_tr_loss = np.round(min(train_loss_list), 2)\n",
        "min_val_loss = np.round(min(val_loss_list), 2)\n",
        "plt.title('Training vs Validation loss for a convolutional autoencoder')\n",
        "plt.legend()\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.savefig('loss.png', dpi = 200)\n",
        "\n",
        "#plt.title(f'minimum train loss = {min_tr_loss}; minimum val loss = {min_val_loss}');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
